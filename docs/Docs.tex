\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{fancyhdr}

\geometry{margin=2.5cm}
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}
\lhead{Analizador de Algoritmos}

% Configuración de listings para código
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
}




\begin{document}

\title{Sistema de Análisis Automático de Complejidad Algorítmica}

\author{
    Juan David Ocampo González \\
    Juan Manoel Miranda Gómez
}

\date{Diciembre 5 de 2025}

\maketitle

\vfill
\begin{center}
    \textbf{Docente:} Luz Enith Guerrero
\end{center}
\vfill
\newpage

\tableofcontents
\newpage

\section{Introducción}

El \textit{Analizador de Algoritmos} es un software desarrollado por un equipo de estudiantes de ingeniería de la Universidad de Caldas, durante el curso de Análisis y Diseño de Algoritmos, dictado por la docente Luz Enith Guerrero.

Este software tiene como función analizar la eficiencia temporal y espacial de algoritmos escritos en pseudocódigo, utilizando métodos vistos en clase con el apoyo de modelos de lenguaje grandes (LLMs) para lograr un análisis más profundo y preciso.

El proyecto nos motivó a reforzar conceptos vistos en clase y a explorar tecnologías emergentes como LangGraph y Gemini para resolver este desafío de forma innovadora.



\section{Análisis del Problema}

Realizar el análisis de complejidad de un algoritmo requiere personas con experiencia y conocimientos avanzados en cálculo, lo que puede tomar horas o incluso días para obtener un aproximado de la eficiencia del algoritmo. Abstraer esta información para que pueda ejecutarse en código era prácticamente imposible antes, ya que no siempre es fácil extraer las ecuaciones de recurrencia o las sumatorias exactas de los algoritmos.

Nuestro \textit{Analizador de Algoritmos} puede recibir tanto lenguaje natural como pseudocódigo, el cual puede contener arreglos, ciclos, llamados a funciones, estructuras condicionales y más. Lo que le permite hacer un analisis que tardaria demaciado tiempo, en cuestion de minutos. 

\subsection{Alcance del Sistema}

Nuestro software tiene un alcance extenso, siendo capaz de procesar:

\begin{itemize}
    \item \textbf{Algoritmos recursivos}: Detección automática de recursión, construcción de relaciones de recurrencia $T(n) = aT(n/b) + f(n)$, y aplicación del teorema maestro.
    \item \textbf{Algoritmos iterativos}: Análisis de ciclos \texttt{for}, \texttt{while}, \texttt{repeat-until}, con soporte para anidamiento múltiple.
    \item \textbf{Estructuras de control}: Condicionales \texttt{if-else} con análisis de mejor, peor y caso promedio.
    \item \textbf{Análisis línea por línea}: Cálculo de costo computacional para cada línea de código.
\end{itemize}

Su única limitación depende del LLM y su respectiva API key. Actualmente utilizamos la API gratuita de Google con los modelos \texttt{gemini-2.5-flash} y \texttt{gemini-2.5-flash-lite}, que con prompts bien diseñados e inputs organizados, son capaces de resolver los algoritmos vistos en clase con una precisión superior al 90\%.

\section{Entrada de Datos y Sintaxis}

La sintaxis del pseudocódigo fue definida por la docente y se estructura de la siguiente manera:

\subsection{Estructuras de Control}

\begin{itemize}
    \item \textbf{FOR}: \texttt{for variableContadora $\leftarrow$ valorInicial to limite do begin ... end}
    \item \textbf{WHILE}: \texttt{while (condicion) do begin ... end}
    \item \textbf{REPEAT}: \texttt{repeat ... until (condicion)}
    \item \textbf{IF}: \texttt{if (condicion) then begin ... end else begin ... end}
\end{itemize}

\subsection{Reglas Generales}

\begin{itemize}
    \item \textbf{Asignación}: Símbolo $\leftarrow$ (no se permiten asignaciones múltiples)
    \item \textbf{Comentarios}: Símbolo $\triangleright$ para el resto de la línea
    \item \textbf{Variables}: Locales al procedimiento (no globales)
    \item \textbf{Acceso a arreglos}: \texttt{A[i]} o \texttt{A[1..j]} para rangos
    \item \textbf{Tamaño de arreglo}: \texttt{length(A)}
    \item \textbf{Declaración de vectores locales}: Al inicio después de \texttt{begin}
\end{itemize}

\subsection{Clases y Objetos}

\begin{itemize}
    \item \textbf{Definición de clase}: \texttt{NombreClase \{atributo1 atributo2 ...\}}
    \item \textbf{Declaración de objeto}: \texttt{Clase nombre\_del\_objeto}
    \item \textbf{Acceso a campos}: \texttt{objeto.campo}
    \item \textbf{Punteros}: Pueden tener valor \texttt{NULL}
\end{itemize}

\subsection{Subrutinas}

\begin{itemize}
    \item \textbf{Definición}: \texttt{nombre\_subrutina(parámetro1, ..., parámetroK) begin ... end}
    \item \textbf{Parámetros arreglo}: \texttt{nombre\_arreglo[n..m]}
    \item \textbf{Parámetros objeto}: \texttt{Clase nombre\_objeto}
    \item \textbf{Llamado}: \texttt{CALL nombre\_subrutina(parámetros)}
\end{itemize}

\subsection{Operadores}

\begin{itemize}
    \item \textbf{Booleanos}: \texttt{and}, \texttt{or}, \texttt{not} (con evaluación perezosa)
    \item \textbf{Valores booleanos}: \texttt{T} (true), \texttt{F} (false)
    \item \textbf{Relacionales}: $<$, $>$, $\leq$, $\geq$, $=$, $\neq$
    \item \textbf{Matemáticos}: $+$, $*$, $/$, $-$, \texttt{mod}, \texttt{div}, $\lceil \cdot \rceil$ (techo), $\lfloor \cdot \rfloor$ (piso)
\end{itemize}

\subsection{Modalidades de Interacción}

El usuario puede interactuar con el sistema de dos formas:

\begin{enumerate}
    \item \textbf{Consola Python}: Ejecución directa mediante scripts Python.
    \item \textbf{Interfaz Gráfica}: Aplicación web desarrollada en React para una experiencia más amigable.
    \item \textbf{API REST}: Endpoints FastAPI para integración con otros sistemas.
\end{enumerate}

Las expresiones en lenguaje natural son evaluadas por Gemini 2.5 Flash, actuando como un copiloto inteligente. Mediante ingeniería de prompts, se le proporciona la sintaxis y reglas del pseudocódigo, lo que le permite interpretar y asistir al usuario con su algoritmo de manera efectiva.

\subsection{Metodología de Desarrollo}

La tecnica que aplicamos fue “divide y venceras”. Dividimos el problema de Analizar un algoritmo, en sub problemas. 
\begin{itemize}
    \item Recibir el lenguaje natural o código
    \item Hacer correcciones de sintaxis
    \item Generar un grafo que representa el código
    \item Generar una expresión matemática que resume la eficiencia del código
    \item Aplicar técnicas iterativas (resolver sumatorias y analizar el código) para la complejidad temporal
    \item Aplicar técnicas recursivas (árboles de recurrencia, teorema maestro, ecuación homogénea y cálculos de sumatorias) para su complejidad temporal
    \item Para el cálculo espacial miramos las variables extras que no son la entrada de datos y hacemos la sumatoria del total de ellas
    \item Organizar los resultados y ponerlos en funciones asintóticas apropiadas
    \item Análisis final y completo por un LLM
\end{itemize}
Lo mas dificil fue realizar el caso promedio. Para eso necesitamos un analisis mas profundo del algoritmo para que se pueda sacar las ecuaciones necesarias para poder resolver. Para eso utilizamos los llms, que seran de apoyo para analizar el codigo como un todo.

\section{Arquitectura e Implementación del Sistema}

\subsection{Patrón Arquitectónico Adoptado}

Nuestro analizador está organizado como una arquitectura \textbf{cliente–servidor por capas}:

\begin{itemize}
    \item \textbf{Capa de presentación}: una pequeña interfaz web en React y, de forma alternativa, la consola de Python.
    \item \textbf{Capa de servicios / API}: un backend en FastAPI que expone un endpoint para enviar el pseudocódigo o la descripción en lenguaje natural.
    \item \textbf{Capa de lógica de negocio}: el motor de análisis implementado con Python y LangGraph, donde se hace todo el trabajo ``duro'' (parseo, generación de AST, análisis iterativo/recursivo, construcción de ecuaciones, etc.).
    \item \textbf{Capa de integración con LLMs y librerías}: aquí se hacen las llamadas a Gemini y a las librerías matemáticas (por ejemplo SymPy), siempre a través de funciones bien separadas.
\end{itemize}

Este esquema nos ayuda a separar la parte visual de la lógica de análisis y de la integración con los modelos de lenguaje.

\subsection{Justificación del Diseño}

Escogimos esta arquitectura por varias razones prácticas:

\begin{itemize}
    \item \textbf{Separación de responsabilidades}: el frontend solo se encarga de mostrar y recoger información del usuario; toda la lógica complicada queda en el backend.
    \item \textbf{Escalabilidad}: si en el futuro queremos soportar más usuarios o más peticiones, podemos escalar el servidor sin tocar la interfaz.
    \item \textbf{Extensibilidad}: podemos cambiar el modelo de lenguaje, agregar nuevas técnicas de análisis o soportar nuevos tipos de algoritmos sin tener que reescribir todo.
    \item \textbf{Interoperabilidad}: al exponer un API REST, otros sistemas podrían usar nuestro analizador sin necesidad de conocer los detalles internos.
\end{itemize}

En resumen, intentamos que el diseño fuera sencillo, pero que nos permitiera crecer si el proyecto se sigue usando más adelante.

\subsection{Diagrama de Arquitectura}

El diagrama de alto nivel incluye los siguientes bloques principales:

\begin{enumerate}
    \item \textbf{Usuario}
    \item \textbf{Interfaz (Web / Consola)}
    \item \textbf{Servidor FastAPI}
    \item \textbf{Motor de análisis (LangGraph + Python)}
    \item \textbf{Parser de pseudocódigo}
    \item \textbf{Módulo de análisis iterativo}
    \item \textbf{Módulo de análisis recursivo}
    \item \textbf{Módulo de integración con LLM (Gemini)}
    \item \textbf{Módulo matemático (SymPy y utilidades)}
\end{enumerate}

Las flechas muestran el flujo básico: el usuario envía el algoritmo $\rightarrow$ la interfaz lo manda al backend $\rightarrow$ el motor analiza y pregunta al LLM cuando es necesario $\rightarrow$ se generan resultados y se devuelven al usuario en formato legible.

\subsection{Componentes del Sistema}

De manera sencilla, los componentes principales son:

\begin{itemize}
    \item \textbf{Módulo de entrada}: recibe el texto (pseudocódigo o lenguaje natural) desde la interfaz o por consola.
    \item \textbf{Analizador léxico y sintáctico}: comprueba que el pseudocódigo cumple la sintaxis definida en clase y construye un árbol de sintaxis (AST) simplificado.
    \item \textbf{Evaluador semántico}: identifica si el algoritmo es iterativo, recursivo o mezcla de ambos y detecta estructuras de control importantes.
    \item \textbf{Módulo de deducción de complejidad iterativa}: convierte ciclos en sumatorias y las resuelve para obtener la complejidad temporal y espacial.
    \item \textbf{Módulo de deducción de complejidad recursiva}: extrae ecuaciones de recurrencia y aplica las técnicas vistas (teorema maestro, árboles de recurrencia, ecuaciones características, etc.).
    \item \textbf{Motor de interacción con el LLM}: encapsula las llamadas a Gemini y devuelve respuestas ya filtradas y con formato.
    \item \textbf{Interfaz de usuario}: muestra el pseudocódigo, las ecuaciones intermedias y la respuesta final ($O$, $\Omega$, $\Theta$) en un formato amigable.
\end{itemize}

\subsection{Flujo de Datos y Lógica Interna}

El recorrido típico de una entrada es el siguiente:

\begin{enumerate}
    \item El usuario escribe un algoritmo en pseudocódigo o una descripción en lenguaje natural.
    \item El backend detecta si el texto parece ya pseudocódigo o si primero debe pasarse por el LLM para generar el pseudocódigo equivalente.
    \item El parser construye un AST y valida la sintaxis según las reglas del curso.
    \item A partir del AST se decide si el algoritmo es principalmente \textbf{iterativo} o \textbf{recursivo}.
    \item Si es iterativo, se generan sumatorias y se resuelven con ayuda de SymPy y reglas básicas.
    \item Si es recursivo, se construye la ecuación de recurrencia y se elige el método más adecuado para resolverla (teorema maestro, iteración, árbol de recurrencia, etc.).
    \item Finalmente se organiza la información: costos por línea, ecuaciones intermedias y complejidades en $O$, $\Omega$ y $\Theta$, y se le pide al LLM que escriba una explicación entendible.
    \item El backend devuelve un JSON con todos los resultados y la interfaz los muestra al usuario.
\end{enumerate}

\subsection{Manejo de Errores y Validación de Entrada}

Para que el sistema no ``se rompa'' con entradas malas, tomamos algunas medidas:

\begin{itemize}
    \item \textbf{Validación de sintaxis}: el parser detecta cuando el pseudocódigo no cumple las reglas (por ejemplo, falta un \texttt{end} o hay un \texttt{for} mal escrito).
    \item \textbf{Mensajes claros}: cuando hay errores de sintaxis, el sistema intenta indicar en qué parte del texto está el problema para que el usuario pueda corregirlo.
    \item \textbf{Correcciones asistidas por LLM}: en algunos casos se le pide al modelo de lenguaje que proponga una versión corregida del código manteniendo la intención del usuario.
    \item \textbf{Manejo de excepciones}: en el backend usamos bloques \texttt{try/except} para capturar fallos inesperados (por ejemplo, una división por cero en una ecuación) y devolver un mensaje de error controlado en lugar de que el programa se cierre.
\end{itemize}

De esta forma, aunque la entrada no sea perfecta, el usuario recibe una respuesta que le explica qué pasó.

\subsection{Estructura del Código y Organización de Archivos}

De forma muy resumida, la organización del proyecto es la siguiente:

\begin{itemize}
    \item \textbf{Carpeta principal del backend (Python):}
    \begin{itemize}
        \item \texttt{app/api.py}: define el endpoint principal donde se recibe el texto a analizar.
        \item \texttt{app/agents/}: contiene el grafo de LangGraph, el estado compartido y los nodos del flujo (decisión inicial, validación, análisis iterativo, análisis recursivo, resultado, etc.).
        \item \texttt{app/agents/tools/}: funciones auxiliares para resolver sumatorias y recurrencias.
        \item \texttt{app/tools/ast\_parser/}: gramática y parser para convertir el pseudocódigo en AST.
    \end{itemize}
    \item \textbf{Archivos de configuración:}
    \begin{itemize}
        \item \texttt{.env}: donde se guarda la API key de Google (no se sube al repositorio).
        \item \texttt{requirements.txt} o \texttt{pyproject.toml}: dependencias del proyecto.
    \end{itemize}
    \item \textbf{Frontend (React):}
    \begin{itemize}
        \item Componentes para el formulario de entrada y la visualización de resultados.
    \end{itemize}
\end{itemize}

Aunque hay más archivos, esta es la estructura básica que usamos para mantener el código ordenado.

\subsection{Integración de LLMs}

Los LLMs son utilizados para las siguientes tareas:

\begin{itemize}
    \item \textbf{Principio de correctitud}: Análisis del código y lenguaje natural
    \item \textbf{Corrección y validación de sintaxis}: Verificación automática del pseudocódigo
    \item \textbf{Parseo de lenguaje natural a pseudocódigo}: Conversión inteligente
    \item \textbf{Auxiliares en la generación de ecuaciones}: Principalmente para el caso promedio
    \item \textbf{Resultado final}: Análisis del algoritmo en lenguaje natural
\end{itemize}

Utilizamos \texttt{gemini-2.5-flash} y \texttt{gemini-2.5-flash-lite} (gratuito). Lo implementamos con \textbf{LangGraph}, un framework para crear agentes que utilizan tanto código escrito manualmente como LLMs para mejorar los resultados.

Con una ingeniería de prompts adecuada y utilizando \textit{tools} (herramientas auxiliares que tiene el propio LangGraph), la fiabilidad del LLM puede llegar a ser superior al 90\%.


\section{Análisis de Eficiencia del Sistema}

\subsection{Bibliotecas y Herramientas Utilizadas}

Las principales bibliotecas utilizadas son:

\begin{itemize}
    \item \href{https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash}{Gemini 2.5 Flash}
    \item \href{https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-lite}{Gemini 2.5 Flash Lite}
    \item \href{https://www.sympy.org/en/index.html}{SymPy} -- Para cálculos simbólicos
\end{itemize}

Cada una tiene su propio costo computacional asociado.

\subsection{Complejidad Temporal del Sistema}

Podemos decir que el costo promedio para nuestra solución es $\Theta(N)$, donde $N$ es la cantidad de líneas de código que se generaron o que se pasaron como entrada.

La ecuación de complejidad vendría a ser:

\[
T(n) = C_1 \cdot N + C_2 \cdot \text{CostoLLM}
\]

Esta complejidad aplica para los 3 casos (mejor, peor y promedio).

\subsection{Comparación de Rendimiento}

\begin{itemize}
    \item \textbf{Modelo más rápido}: Gemini 2.5 Flash Lite, que responde 3 a 4 veces más rápido que Gemini 2.5 Flash.
    
    \item \textbf{Comparación manual vs. sistema}: 
    \begin{itemize}
        \item En la comparación de análisis manual (mandar un prompt único) vs. utilizar nuestro algoritmo, se notan dos aspectos importantes:
        \item El tiempo de análisis manual con prompt directo reduce mucho, pero la veracidad de la información también se reduce significativamente.
        \item Nuestro algoritmo tiene complejidad $O(N)$, pero todos los procesos realizados son para abstraer la información del algoritmo y dejarlo lo más matemático posible, permitiendo que el LLM haga pequeños ajustes en la ecuación generada para los 3 casos.
    \end{itemize}
    
    \item \textbf{Reducción de alucinaciones}: Como trabajamos con agentes, hay LLMs especializados para resolver problemas específicos. En comparación con un LLM normal de aplicativo, que cuanto más se pregunta, más empieza a olvidar o asumir cosas que no son ciertas (lo que reduce su precisión), nuestro sistema mantiene mayor coherencia y precisión.
\end{itemize}

\section{Pruebas}

Además de las figuras incluidas, probamos el sistema con varios algoritmos clásicos, tanto iterativos como recursivos. Algunos ejemplos son:

\begin{itemize}
    \item Búsqueda lineal y búsqueda binaria.
    \item Ordenamiento burbuja, inserción y mergesort.
    \item Cálculo de factorial, Fibonacci, Torres de Hanoi.
    \item Problemas vistos en clase como cambio de monedas o multiplicación de matrices.
\end{itemize}

Para cada algoritmo comparamos la complejidad que entrega el analizador con la complejidad teórica esperada. En la mayoría de los casos los resultados coinciden. Los principales problemas aparecieron cuando:

\begin{itemize}
    \item El pseudocódigo no seguía exactamente la sintaxis definida por la profesora.
    \item Faltaba información para el caso promedio (por ejemplo, probabilidades en un \texttt{if}).
\end{itemize}

En esos casos el sistema informa la ambigüedad y aclara que la respuesta puede ser aproximada.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/Picture1.png}
    \caption{Ejemplo de prueba 1}
    \label{fig:prueba1}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/Picture2.png}
    \caption{Ejemplo de prueba 2}
    \label{fig:prueba2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/Picture3.png}
    \caption{Ejemplo de prueba 3}
    \label{fig:prueba3}
\end{figure}


\section{Conclusiones y Recomendaciones}

\subsection{Conclusiones}
Implementar frameworks mas rápidos que LangGraph para optimizar tiempos de
respuesta
Expandir el soporte para más estructuras de datos complejas
Mejorar la interfaz de usuario con visualizaciones interactivas
Agregar soporte para análisis de algoritmos paralelos y distribuidos
En este proyecto se aprende incluso cómo funciona el propio cerebro para hacer el análisis, ya que nos tocó abstraer absolutamente toda nuestra línea de razonamiento para poder pasarla a código. Desde la generación de un AST simplificado, ecuaciones intermediarias, y análisis completo para extraer el caso promedio, fue un ejercicio bien interesante y gratificador que nos hizo reforzar y buscar nuevos conocimientos.

El desarrollo de este sistema permitió:

\begin{itemize}
    \item Comprender profundamente los conceptos de análisis de algoritmos
    \item Aplicar técnicas de ingeniería de software modernas
    \item Integrar inteligencia artificial de manera efectiva en la resolución de problemas complejos
    \item Crear una herramienta útil para estudiantes y profesionales
\end{itemize}

\subsection{Recomendaciones para Mejoras Futuras}

Para mejoras futuras, consideramos que podríamos:

\begin{itemize}
    \item Utilizar otros modelos más especializados en código (como Codex o CodeLlama)
    \item Implementar frameworks más rápidos que LangGraph para optimizar tiempos de respuesta
    \item Expandir el soporte para más estructuras de datos complejas
    \item Mejorar la interfaz de usuario con visualizaciones interactivas
    \item Agregar soporte para análisis de algoritmos paralelos y distribuidos
\end{itemize}


\section{Manual Técnico}

\subsection{Objetivo del Manual}

Este manual está dirigido a personas que quieran \textbf{instalar, configurar o modificar} el analizador. Explica qué se necesita, cómo ejecutar el proyecto y cómo está organizado el código.

\subsection{Requisitos del Sistema}

\begin{itemize}
    \item Python 3.10 o superior.
    \item Conexión a internet para usar la API de Gemini.
    \item Navegador web moderno (para la interfaz).
    \item Opcional: Node.js y npm si se quiere levantar el frontend en React.
\end{itemize}

\subsection{Instalación y Configuración Básica}

\begin{enumerate}
    \item Clonar el repositorio del proyecto.
    \item Crear y activar un entorno virtual de Python.
    \item Instalar las dependencias con \texttt{pip install -r requirements.txt} (o el archivo equivalente).
    \item Crear un archivo \texttt{.env} con la API key de Google (\texttt{GOOGLE\_API\_KEY=...}).
    \item Ejecutar el backend con \texttt{uvicorn app.api:app --reload} (o el comando que definimos en el README).
\end{enumerate}

Si se usa la interfaz en React, se entra a la carpeta del frontend, se ejecuta \texttt{npm install} y luego \texttt{npm run dev} o similar.

\subsection{Ejecución del Sistema}

\begin{itemize}
    \item \textbf{Solo backend}: se puede probar el endpoint desde \texttt{/docs} (documentación automática de FastAPI) enviando el algoritmo en el campo de texto.
    \item \textbf{Backend + frontend}: el usuario entra a la URL del frontend, escribe el algoritmo y pulsa el botón de analizar; el frontend llama al backend por HTTP.
\end{itemize}

\subsection{Estructura Básica del Código}

En esta parte del manual técnico basta con referenciar la sección 4.7 del informe, donde se describe la organización de carpetas y archivos. Si el proyecto crece, aquí se pueden agregar más detalles (por ejemplo, sobre pruebas automatizadas o despliegue en la nube).


\section{Manual de Usuario}

\subsection{Inicio Rápido}

\begin{enumerate}
    \item Abrir la aplicación web o, en su defecto, ejecutar el script de consola.
    \item Elegir si se va a escribir \textbf{pseudocódigo} o una \textbf{descripción en lenguaje natural}.
    \item Pegar o escribir el algoritmo en el cuadro de texto.
    \item Pulsar el botón ``Analizar''.
\end{enumerate}

\subsection{Análisis de Algoritmos en Pseudocódigo}

\begin{itemize}
    \item Escribir el algoritmo siguiendo la sintaxis que se usó en clase (palabras reservadas, \texttt{begin/end}, \texttt{for}, \texttt{while}, etc.).
    \item Verificar que todas las estructuras estén bien cerradas.
    \item El sistema devolverá:
    \begin{itemize}
        \item La complejidad temporal en $O$, $\Omega$ y $\Theta$.
        \item Una idea de la complejidad espacial.
        \item Una explicación en lenguaje sencillo de cómo se obtuvo el resultado.
    \end{itemize}
\end{itemize}

\subsection{Análisis desde Lenguaje Natural}

\begin{itemize}
    \item En este modo el usuario puede escribir algo como: ``ordenar un arreglo con mergesort'' o ``calcular el factorial de n de forma recursiva''.
    \item El sistema primero genera un pseudocódigo aproximado usando el LLM y luego lo analiza como en el caso anterior.
    \item Es posible que la explicación indique que el algoritmo fue ``interpretado'' a partir de la descripción.
\end{itemize}

\subsection{Lectura de Resultados}

En la interfaz se muestran, de forma resumida:

\begin{itemize}
    \item Las ecuaciones clave (sumatorias o recurrencias).
    \item La notación asintótica final.
    \item Un breve comentario con el tipo de algoritmo (por ejemplo, ``divide y vencerás'', ``resta y vencerás'', etc.).
\end{itemize}

El objetivo es que el usuario no solo vea la respuesta, sino que también entienda de dónde salió.

\subsection{Mensajes de Error Frecuentes}

Algunos mensajes que puede mostrar el sistema:

\begin{itemize}
    \item \textbf{``Error de sintaxis''}: el pseudocódigo no cumple la gramática esperada (por ejemplo, falta un \texttt{end}).
    \item \textbf{``No se pudo extraer la recurrencia''}: el algoritmo recursivo es demasiado complejo o no sigue los patrones soportados.
    \item \textbf{``Entrada ambigua''}: falta información para determinar el caso promedio o ciertos detalles de la lógica.
\end{itemize}

En todos estos casos el sistema intenta sugerir al usuario qué puede corregir.


\section{Anexos}

Para cerrar el informe, incluimos como anexos:

\begin{itemize}
    \item \textbf{Código fuente documentado}: enlace al repositorio oficial del proyecto.
    \item \textbf{Lista de algoritmos de prueba}: con su complejidad esperada.
    \item \textbf{Capturas de pantalla de la interfaz}: mostrando ejemplos completos de uso.
\end{itemize}

Estos anexos no son obligatorios para entender el informe, pero ayudan a mostrar el alcance real del sistema y facilitan que otras personas puedan reutilizarlo o mejorarlo.


\section{Codigo}
\begin{itemize}
    \item \href{https://github.com/Jhonder18/Agent_Algorithms.git}{Codigo Backend}
    \item \href{https://github.com/Jhonder18/analizador-complejidades-frontend.git}{Codigo Frontend}
\end{itemize}

\end{document}


