# Agent Algorithms ‚Äì Arquitectura y Flujos

Este documento resume c√≥mo est√° organizada la aplicaci√≥n, qu√© agentes intervienen en cada etapa del pipeline y qu√© pruebas conviene ejecutar para validar cambios.

## Visi√≥n general

- **Tecnolog√≠as clave:** FastAPI para el servicio HTTP, LangGraph para orquestar los nodos del pipeline, Lark para el parser determin√≠stico de pseudoc√≥digo y un proveedor LLM (Gemini por defecto) para normalizaci√≥n, validaci√≥n asistida, c√°lculos de costos y res√∫menes.
- **Entrada principal:** peticiones `POST /api/v2/analyze` con texto o pseudoc√≥digo. El request inicial se transforma en un estado `AnalyzerState` que viaja por LangGraph.
- **Salida:** un diccionario con el pseudoc√≥digo corregido, AST, costos, soluci√≥n de complejidad y metadatos; opcionalmente se adjunta un resumen natural en la √∫ltima etapa.

## Flujo del pipeline

1. **Router START ‚Üí normalize|validate**
   - `route_from_start` usa el `planner` (LLM opcional) o una heur√≠stica en `_heuristic_router`.
   - Criterio: presencia de keywords como `begin`, `for`, `if` o el s√≠mbolo `ü°®`.

2. **normalize (`app/agents/nodes/normalize.py`)**
   - Detecta si el texto ya es pseudoc√≥digo can√≥nico (keywords en ingl√©s, `begin/end`, flecha `ü°®`).
   - Si no lo es, llama a `get_llm` con un prompt estricto que exige estructuras bien formadas, flechas correctas, bloques `begin/end` en loops y condicionales, etc.
   - Devuelve `pseudocode` y marca metadatos `input_type`, `used_normalization`.

3. **validate (`app/agents/nodes/validate.py`)**
   - Aplica `_simple_normalize` (flechas, keywords a min√∫scula, `CALL` en may√∫sculas, newline final) y `_ensure_balanced_blocks` para a√±adir `end` faltantes.
   - Ejecuta el parser Lark mediante `get_parser_agent().parser.parse`.
   - Si falla, `_repair_with_llm` recibe el error de Lark + gram√°tica completa. Tras la respuesta del LLM se vuelve a balancear `begin/end` y se reintenta con Lark.
   - Registra normalizaciones (incluyendo res√∫menes del LLM) y devuelve `validation` + el pseudoc√≥digo corregido.

4. **ast (`app/agents/nodes/ast_tool_node.py`)**
   - Invoca la herramienta estructurada `ast_parse_lc` (LangChain StructuredTool) que interna¬≠mente usa `ParserAgent`.
   - El AST se construye con los nodos tipados de `app/tools/ast_parser/ast_nodes.py`, con soporte para:
     - Sentencias (`Assign`, `If`, `While`, `For`, `CallStatement`, `VarDeclaration`, `ActionStatement`, etc.).
     - Expresiones (`Call`, `ArrayAccess`, `ArrayLiteral`, `BinOp`, `UnOp`, `Compare`, `Literal`).
   - Se adjunta `metadata` con el n√∫mero total de nodos para uso posterior.

5. **costs (`app/agents/nodes/costs.py`)**
   - Si el AST no existe o llega con `success=False`, el nodo corta la ejecuci√≥n y devuelve costos vac√≠os (`success=False`, `error` descriptivo). Esto evita pedir al LLM c√°lculos inventados.
   - Cuando hay AST v√°lido, se llama a `llm_json_call` con un prompt que exige:
     - Costos por nodo (`per_node`) con `line_start/end`, `cost` y `own_cost`.
     - Costos por l√≠nea (`per_line`) con operaciones simb√≥licas.
     - Totales agregados (`total`).
   - Los resultados incluyen `success=True` y metadatos `costs_nodes`, `costs_lines`.

6. **solve (`app/agents/nodes/solve.py`)**
   - Si `costs.success` es falso, se retorna un bloque con `N/A` y el error propagado.
   - En caso contrario, el prompt `SOLVE_SYS` pide pasos algebr√°icos y cotas (`exact`, `big_o`, `bounds`).
   - El nodo empaqueta `result` con todo lo calculado y actualiza metadatos (`final_pseudocode`, `total_nodes_analyzed`, etc.).

7. **summarize (`app/agents/nodes/summarize.py`)**
   - Opcional; usa el LLM para generar un resumen t√©cnico de 4-6 l√≠neas basado en `state["result"]`.

El flujo finaliza en `END` y la respuesta JSON se env√≠a de vuelta al cliente FastAPI.

## Arquitectura de carpetas relevantes

```
app/
‚îú‚îÄ‚îÄ api.py                # FastAPI con /api/v2/analyze y /health
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ graph.py          # Construye el StateGraph y rutas
‚îÇ   ‚îú‚îÄ‚îÄ planner.py        # Decide normalize vs validate (heur√≠stico o LLM)
‚îÇ   ‚îú‚îÄ‚îÄ nodes/            # Nodos normalize, validate, ast, costs, solve, summarize
‚îÇ   ‚îî‚îÄ‚îÄ state.py          # TypedDict AnalyzerState + helper update_metadata
‚îú‚îÄ‚îÄ constants.py          # Define ARROW (ü°®) y otras constantes globales
‚îú‚îÄ‚îÄ services/llm.py       # get_llm, strip_code_fences y llm_json_call
‚îî‚îÄ‚îÄ tools/ast_parser/
    ‚îú‚îÄ‚îÄ ast_nodes.py      # Definici√≥n del IR tipado
    ‚îú‚îÄ‚îÄ parser_agent.py   # Lark + Transformer + Singleton
    ‚îú‚îÄ‚îÄ ast_parser.py     # StructuredTool + compatibilidad build_ast
    ‚îî‚îÄ‚îÄ grammar/          # Gram√°tica Lark (*.lark)
```

## L√≥gica de parsing y transformaci√≥n

- `grammar.lark` define la sintaxis de pseudoc√≥digo (procedimientos, bucles, condicionales, asignaciones, llamadas, arrays, literales, comentarios con `‚ñ∫`, etc.).
- `PseudocodeToASTTransformer` convierte los √°rboles de Lark en nodos Python, conservando `line_start/line_end` gracias a `propagate_positions=True`.
- El m√≥dulo crea un `ParserAgent` singleton para evitar recargar la gram√°tica en cada llamada; `get_parser_agent` mueve todo el parsing a memoria compartida.
- `create_toolkit()` expone `ast_parse_lc`, permitiendo integrar la tool en LangGraph o en cualquier agente LangChain que soporte herramientas.

## Estrategia de robustez

- **Balance de bloques:** `_ensure_balanced_blocks` a√±ade `end` faltantes tras normalizaci√≥n o reparaci√≥n con LLM.
- **Validaciones en cadena:** cada nodo comprueba que el paso anterior haya tenido √©xito antes de continuar, anotando `success`/`error` en la carga √∫til.
- **LLM JSON fallback:** `llm_json_call` intenta volver a pedir al modelo un JSON v√°lido si el primero falla al parsearse.
- **Metadatos centralizados:** `update_metadata` evita duplicar l√≥gica al propagar informaci√≥n a trav√©s del estado global.

## Casos de prueba recomendados

1. **Pseudoc√≥digo v√°lido sin intervenci√≥n LLM**
   - Input: algoritmo cl√°sico (ej. burbuja) ya can√≥nico.
   - Expectativa: `normalize.used_normalization=False`, `validation.era_algoritmo_valido=True`, `costs.success=True`, `solve.success=True`.

2. **Texto en lenguaje natural**
   - Input: descripci√≥n en espa√±ol.
   - Verificar que `normalize` invoque al LLM, genere pseudoc√≥digo con flechas `ü°®` y se agregue `metadata.used_normalization=True`.

3. **Pseudoc√≥digo con `begin/end` faltantes**
   - Input: loops o condicionales sin `end` de cierre.
   - Asegurar que `_ensure_balanced_blocks` a√±ada los cierres antes de pasar a Lark y que `normalizaciones` registre la acci√≥n.

4. **Errores de sintaxis complejos**
   - Input: pseudoc√≥digo con `repeat` mal formado, `CALL` en min√∫sculas o literales de arreglos.
   - Verificar que tras la reparaci√≥n con LLM, `validation.parser_ok=True` y que el AST incluya nodos `CallStatement`, `ArrayLiteral`, etc.

5. **Fallos controlados**
   - Forzar un error en el parser (por ejemplo, s√≠mbolos ajenos a la gram√°tica) y comprobar que:
     - `validation.errores` documente el fallo.
     - `costs_node` devuelva `success=False` sin invocar al LLM.
     - `solve_node` propague `N/A` y el mensaje de error.

6. **Integraci√≥n API**
   - Ejecutar `python main.py` (Uvicorn) y hacer requests reales contra `/api/v2/analyze` para confirmar que se reciben todos los campos (`validation`, `ast`, `costs`, `solution`, `metadata`, `summary`).

Para automatizar, puedes mockear `get_llm` con el `provider=stub` (`LLM_PROVIDER=stub`) y as√≠ simular respuestas deterministas durante pruebas unitarias o integraci√≥n ligera.

